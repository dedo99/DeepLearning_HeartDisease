{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d8dc76a",
   "metadata": {},
   "source": [
    "# Librerie e funzioni d'utilitÃ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3eb444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wfdb as wf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import shutil\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d784fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "blu_fiordaliso = \"#6495ED\"\n",
    "lilla = \"#c8a2c8\"\n",
    "nero = \"#000000\"\n",
    "gradient = [\"#ffffff\", \"#dcc4dc\",\"#c8a2c8\", \"#a787ad\", \"#93779c\", \"#735d82\", \"#6c4675\"]\n",
    "my_cmap1 = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc13143",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[149030, 34],[7442, 12]])\n",
    "norm = matplotlib.colors.Normalize(matrix.min(), matrix.max())\n",
    "boundaries = [value for value in matrix.flatten().tolist()]\n",
    "list.sort(boundaries)\n",
    "colors = [[norm(boundaries[0]), \"#dcc4dc\"], \n",
    "          [norm(boundaries[1]), \"#c8a2c8\"], \n",
    "          [norm(boundaries[2]), \"#93779c\"], \n",
    "          [norm(boundaries[3]), \"#6c4675\"]]\n",
    "my_cmap2 = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f22405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_and_make_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        os.mkdir(path)\n",
    "    else:\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "heartbeats_datasets = \"heartbeats_dataset.csv\"\n",
    "base_heartbeats_path = \".\\\\heartbeats\\\\\"\n",
    "plot_path = \".\\\\plot\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_and_make_dir(base_heartbeats_path)\n",
    "remove_and_make_dir(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_dataset = \".\\\\mitdb\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory \"mitdb\" and download dataset\n",
    "if not os.path.exists(directory_dataset):\n",
    "    os.mkdir(directory_dataset)\n",
    "    wfdb.dl_database(\"mitdb\", directory_dataset)\n",
    "\n",
    "# wf.io.show_ann_classes()\n",
    "# wf.io.show_ann_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f8515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.io.show_ann_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f868d5",
   "metadata": {},
   "source": [
    "# Distribuzione etichette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract filename from directory\n",
    "list_of_file = list(set([x.rsplit('.', 1)[0] for x in os.listdir(directory_dataset)]))\n",
    "list_of_file.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a05f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = filename, value = [record(tuple), annotation(array)]\n",
    "dataset = {}\n",
    "\n",
    "for filename in list_of_file:\n",
    "    file = os.path.join(directory_dataset, filename)\n",
    "    \n",
    "    # read the file\n",
    "    record = wf.rdsamp(file)\n",
    "    annotation = wf.rdann(file, 'atr')\n",
    "    dataset[filename] = [record, annotation]\n",
    "    \n",
    "    # info about the data\n",
    "    print(\"File:\", file)\n",
    "    print(\"Sampling frequency:\", record[1].get(\"fs\"))\n",
    "    print(\"Data shape:\", record[0].shape)\n",
    "    print(\"Annotations:\", len(annotation.num))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of annotation\n",
    "labels = {}\n",
    "for record in dataset.values():\n",
    "    annotypes = np.array(record[1].symbol)\n",
    "    for label in annotypes:\n",
    "        if label in labels.keys():\n",
    "            labels[label] += 1\n",
    "        else:\n",
    "            labels[label] = 1\n",
    "labels = dict(sorted(labels.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa1f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bar chart esteso\n",
    "def bar_plot_ex(keys, values, title, path, dim):\n",
    "    plt.figure(figsize=dim) \n",
    "    plt.yscale(\"log\")\n",
    "    plt.grid(color=nero, linestyle='-', linewidth=0.5, axis=\"y\")\n",
    "    plt.title(title)\n",
    "    p = plt.bar(keys, values, width=1, color=lilla, edgecolor=nero, linewidth=0.5, align='center')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.savefig(plot_path + path, bbox_inches='tight', transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = labels.keys()\n",
    "values = [item for item in labels.values()]\n",
    "title = \"Distribuzione delle label nel dataset\"\n",
    "file_name = \"\".join(title.lower()).replace(\" \", \"_\")\n",
    "dim = (20,5)\n",
    "bar_plot_ex(keys, values, title, file_name, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a59f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {}\n",
    "for key, record in dataset.items():\n",
    "    annotypes = np.array(record[1].symbol)\n",
    "    tmp[key] = dict.fromkeys(labels.keys(), 0)\n",
    "    for label in annotypes:\n",
    "        tmp[key][label] = tmp[key][label] + 1\n",
    "\n",
    "df = pd.DataFrame.from_dict(tmp)\n",
    "df = df.replace(0, np.nan)\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d4806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20)) \n",
    "title = \"Distribuzione label per file\"\n",
    "file_name = \"\".join(title.lower()).replace(\" \", \"_\")\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel(\"Label\")\n",
    "ax.set_ylabel(\"File\")\n",
    "heatmap = sns.heatmap(df, ax=ax, annot=True, fmt=\".0f\", cmap=\"Purples\", cbar_kws={\"shrink\": .5})\n",
    "a = heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation = 0, fontsize = 12)\n",
    "b = heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation = 0, fontsize = 12)\n",
    "fig.savefig(plot_path + file_name, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f595ea",
   "metadata": {},
   "source": [
    "# Plot ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ecg(channel, sample_start, sample_size, record, annotation):\n",
    "    # get data and annotations for the samples selected below\n",
    "    sample_end = sample_start + sample_size\n",
    "    signal = record[0][sample_start:sample_end, channel]\n",
    "\n",
    "    # plot the heart beats\n",
    "    # time scale is number of readings divided by sampling frequency\n",
    "    times = (np.arange(sample_size, dtype = 'float') + sample_start) / record[1].get('fs')\n",
    "    plt.figure(figsize=(20,7))\n",
    "    plt.plot(times, signal)\n",
    "\n",
    "    # extract annotations\n",
    "    where = np.logical_and(annotation.sample >= sample_start, annotation.sample < sample_end)\n",
    "    annots = annotation.sample[where] - sample_start\n",
    "    annotypes = np.array(annotation.symbol)\n",
    "    annotypes = annotypes[where]\n",
    "\n",
    "    # plot the annotations\n",
    "    annotimes = times[annots]\n",
    "    plt.plot(annotimes, np.ones_like(annotimes) * signal.max() * 1.4, 'ro')\n",
    "\n",
    "    # annotation codes\n",
    "    for idx, annot in enumerate(annots):\n",
    "        plt.annotate(annotypes[idx], xy = (times[annot], signal.max() * 1.1))\n",
    "\n",
    "    plt.xlim([sample_start / record[1].get('fs'), (sample_end / record[1].get('fs'))])\n",
    "    plt.xlabel('Offset')\n",
    "    plt.ylabel(record[1].get('sig_name')[channel])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ccb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 2 channels -> MLII wave = 0\n",
    "channel = 0             \n",
    "\n",
    "# start of the sample in the file\n",
    "sample_start = 0        \n",
    "\n",
    "# number of readings (360 per second)\n",
    "sample_size = 4000      \n",
    "\n",
    "record = dataset[\"100\"][0]\n",
    "annotation = dataset[\"100\"][1]\n",
    "\n",
    "plot_ecg(channel, sample_start, sample_size, record, annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0dc6da",
   "metadata": {},
   "source": [
    "# Creazione dataset di heartbeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heartbeat(channel, sample_start, sample_size, record, annotation):\n",
    "\n",
    "    sample_end = sample_start + sample_size\n",
    "    signal = record[0][sample_start:sample_end, channel]\n",
    "\n",
    "    times = (np.arange(sample_size, dtype = 'float') + sample_start) / record[1].get('fs')\n",
    "\n",
    "    where = np.logical_and(annotation.sample >= sample_start, annotation.sample < sample_end)\n",
    "    annots = annotation.sample[where] - sample_start\n",
    "    annotypes = np.array(annotation.symbol)\n",
    "    annotypes = annotypes[where]\n",
    "\n",
    "    annotimes = times[annots]\n",
    "    \n",
    "    return (signal, times, annotypes, annotimes, annots)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heartbeat(signal, times, annotypes, annotimes, annots):\n",
    "\n",
    "    plt.figure(figsize=(20,7))\n",
    "    plt.plot(times, signal)\n",
    "    plt.plot(annotimes, np.ones_like(annotimes) * signal.max() * 1.4, 'ro')\n",
    "\n",
    "    for idx, annot in enumerate(annots):\n",
    "        plt.annotate(annotypes[idx], xy = (times[annot], signal.max() * 1.1))\n",
    "\n",
    "    plt.xlabel('Offset')\n",
    "    plt.ylabel(record[1].get('sig_name')[channel])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0             \n",
    "heartbeat_size = 300 \n",
    "ds = []\n",
    "for key in dataset.keys():\n",
    "    record = dataset[key][0]\n",
    "    annotation = dataset[key][1]\n",
    "    for pos_of_annotation in annotation.sample:\n",
    "        heartbeat_start = 0 if (pos_of_annotation - 149) < 0 else pos_of_annotation - 149\n",
    "        ds.append(get_heartbeat(channel, heartbeat_start, heartbeat_size, record, annotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ds, columns=[\"signal\", \"times\", \"annotypes\", \"annotimes\", \"annots\"])\n",
    "# plot_heartbeat(df[\"signal\"][0], df[\"times\"][0],df[\"annotypes\"][0], df[\"annotimes\"][0], df[\"annots\"][0])\n",
    "print(\"Numero record:\", len(df))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5364cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete heartbeat with more one annotation and with len of signal less 300 and make dataset for neural network\n",
    "df1 = df[[\"signal\", \"annotypes\"]]\n",
    "df1 = df1[df1['annotypes'].str.len() == 1]\n",
    "df1 = df1[df1['signal'].str.len() == 300]\n",
    "print(\"Numero record:\", len(df1))\n",
    "display(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8998242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.to_csv(base_heartbeats_path + heartbeats_datasets, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1bbdf4",
   "metadata": {},
   "source": [
    "# Addestramento modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from d2l import tensorflow as d2l\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[(df1['annotypes'] == 'N') | (df1['annotypes'] == 'L')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['signal'].tolist()\n",
    "\n",
    "ann = df2['annotypes'].tolist()\n",
    "tmp = LabelEncoder().fit_transform(ann)\n",
    "tmp = tmp.reshape(len(tmp), 1)\n",
    "y = OneHotEncoder(sparse=False, categories='auto').fit_transform(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9895b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d53c6b",
   "metadata": {},
   "source": [
    "### Modello 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"valid\", input_shape=[300, 1]),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"valid\"),\n",
    "    keras.layers.MaxPooling1D(pool_size=2, strides=2),\n",
    "    keras.layers.Conv1D(filters=128, kernel_size=3, strides=1, padding=\"valid\"),\n",
    "    keras.layers.Conv1D(filters=128, kernel_size=3, strides=1, padding=\"valid\"),\n",
    "    keras.layers.MaxPooling1D(pool_size=2, strides=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071bc182",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e3852e",
   "metadata": {},
   "source": [
    "### Modello 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tot = Input(shape=(300, 1), name =\"Input_tot\")\n",
    "\n",
    "# Pipeline 1\n",
    "branch1_1 = keras.layers.Conv1D(filters=8, kernel_size=4, activation='relu', name =\"branch1_1\")(input_tot)\n",
    "branch1_2 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch1_2\")(branch1_1)\n",
    "branch1_3 = keras.layers.Conv1D(filters=24, kernel_size=6, activation='relu', name =\"branch1_3\")(branch1_2)\n",
    "branch1_4 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch1_4\")(branch1_3)\n",
    "\n",
    "# Pipeline 2\n",
    "branch2_1 = keras.layers.Conv1D(filters=8, kernel_size=6, activation='relu', name =\"branch2_1\")(input_tot)\n",
    "branch2_2 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch2_2\")(branch2_1)\n",
    "branch2_3 = keras.layers.Conv1D(filters=24, kernel_size=8, activation='relu', name =\"branch2_3\")(branch2_2)\n",
    "branch2_4 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch2_4\")(branch2_3)\n",
    "\n",
    "# Pipeline 3\n",
    "branch3_1 = keras.layers.Conv1D(filters=8, kernel_size=8, activation='relu', name =\"branch3_1\")(input_tot)\n",
    "branch3_2 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch3_2\")(branch3_1)\n",
    "branch3_3 = keras.layers.Conv1D(filters=24, kernel_size=10, activation='relu', name =\"branch3_3\")(branch3_2)\n",
    "branch3_4 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch3_4\")(branch3_3)\n",
    "\n",
    "# Merging tre pipeline\n",
    "branch_concatenate = concatenate([branch1_4,branch2_4,branch3_4], axis=1, name=\"concatenated_layer\")\n",
    "\n",
    "# Final Layer\n",
    "dense1 = Dense(256, activation = \"sigmoid\", name = \"dense1\")(branch_concatenate)\n",
    "dense2 = Dense(32, activation = \"sigmoid\", name = \"dense2\")(dense1)\n",
    "output_layer = Dense(4, activation = \"sigmoid\", name = \"output_layer\")(dense2)\n",
    "\n",
    "# Model Definition\n",
    "model = Model(inputs=[input_tot], outputs=[output_layer])\n",
    "\n",
    "#Model Details\n",
    "model.summary()\n",
    "# keras.utils.plot_model(model, \"output/architecture.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b9b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rate = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc074ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f6c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
