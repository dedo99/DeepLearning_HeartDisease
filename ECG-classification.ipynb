{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d8dc76a",
   "metadata": {},
   "source": [
    "# Librerie e funzioni d'utilitÃ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3eb444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wfdb as wf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "import shutil\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d784fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "blu_fiordaliso = \"#6495ED\"\n",
    "lilla = \"#c8a2c8\"\n",
    "nero = \"#000000\"\n",
    "gradient = [\"#ffffff\", \"#dcc4dc\",\"#c8a2c8\", \"#a787ad\", \"#93779c\", \"#735d82\", \"#6c4675\"]\n",
    "my_cmap1 = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc13143",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[149030, 34],[7442, 12]])\n",
    "norm = matplotlib.colors.Normalize(matrix.min(), matrix.max())\n",
    "boundaries = [value for value in matrix.flatten().tolist()]\n",
    "list.sort(boundaries)\n",
    "colors = [[norm(boundaries[0]), \"#dcc4dc\"], \n",
    "          [norm(boundaries[1]), \"#c8a2c8\"], \n",
    "          [norm(boundaries[2]), \"#93779c\"], \n",
    "          [norm(boundaries[3]), \"#6c4675\"]]\n",
    "my_cmap2 = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f22405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_and_make_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        os.mkdir(path)\n",
    "    else:\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "heartbeats_datasets = \"heartbeats_dataset.json\"\n",
    "base_heartbeats_path = \".\\\\heartbeats\\\\\"\n",
    "plot_path = \".\\\\plot\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_and_make_dir(base_heartbeats_path)\n",
    "# remove_and_make_dir(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_dataset = \".\\\\mitdb\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory \"mitdb\" and download dataset\n",
    "if not os.path.exists(directory_dataset):\n",
    "    os.mkdir(directory_dataset)\n",
    "    wfdb.dl_database(\"mitdb\", directory_dataset)\n",
    "\n",
    "# wf.io.show_ann_classes()\n",
    "# wf.io.show_ann_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f8515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.io.show_ann_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f868d5",
   "metadata": {},
   "source": [
    "# Distribuzione etichette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract filename from directory\n",
    "list_of_file = list(set([x.rsplit('.', 1)[0] for x in os.listdir(directory_dataset)]))\n",
    "list_of_file.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a05f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = filename, value = [record(tuple), annotation(array)]\n",
    "dataset = {}\n",
    "\n",
    "for filename in list_of_file:\n",
    "    file = os.path.join(directory_dataset, filename)\n",
    "    \n",
    "    # read the file\n",
    "    record = wf.rdsamp(file)\n",
    "    annotation = wf.rdann(file, 'atr')\n",
    "    dataset[filename] = [record, annotation]\n",
    "    \n",
    "    # info about the data\n",
    "    print(\"File:\", file)\n",
    "    print(\"Sampling frequency:\", record[1].get(\"fs\"))\n",
    "    print(\"Data shape:\", record[0].shape)\n",
    "    print(\"Annotations:\", len(annotation.num))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of annotation\n",
    "labels = {}\n",
    "for record in dataset.values():\n",
    "    annotypes = np.array(record[1].symbol)\n",
    "    for label in annotypes:\n",
    "        if label in labels.keys():\n",
    "            labels[label] += 1\n",
    "        else:\n",
    "            labels[label] = 1\n",
    "labels = dict(sorted(labels.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa1f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bar chart esteso\n",
    "def bar_plot_ex(keys, values, title, path, dim):\n",
    "    plt.figure(figsize=dim) \n",
    "    plt.yscale(\"log\")\n",
    "    plt.grid(color=nero, linestyle='-', linewidth=0.5, axis=\"y\")\n",
    "    plt.title(title)\n",
    "    p = plt.bar(keys, values, width=1, color=lilla, edgecolor=nero, linewidth=0.5, align='center')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.savefig(plot_path + path, bbox_inches='tight', transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = labels.keys()\n",
    "values = [item for item in labels.values()]\n",
    "title = \"Distribuzione delle label nel dataset\"\n",
    "file_name = \"\".join(title.lower()).replace(\" \", \"_\")\n",
    "dim = (10,5)\n",
    "bar_plot_ex(keys, values, title, file_name, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a59f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {}\n",
    "for key, record in dataset.items():\n",
    "    annotypes = np.array(record[1].symbol)\n",
    "    tmp[key] = dict.fromkeys(labels.keys(), 0)\n",
    "    for label in annotypes:\n",
    "        tmp[key][label] = tmp[key][label] + 1\n",
    "\n",
    "df = pd.DataFrame.from_dict(tmp)\n",
    "df = df.replace(0, np.nan)\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d4806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20)) \n",
    "title = \"Distribuzione label per file\"\n",
    "file_name = \"\".join(title.lower()).replace(\" \", \"_\")\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel(\"Label\")\n",
    "ax.set_ylabel(\"File\")\n",
    "heatmap = sns.heatmap(df, ax=ax, annot=True, fmt=\".0f\", cmap=\"Purples\", cbar_kws={\"shrink\": .5})\n",
    "a = heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation = 0, fontsize = 12)\n",
    "b = heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation = 0, fontsize = 12)\n",
    "fig.savefig(plot_path + file_name, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f595ea",
   "metadata": {},
   "source": [
    "# Plot ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ecg(channel, sample_start, sample_size, record, annotation):\n",
    "    # get data and annotations for the samples selected below\n",
    "    sample_end = sample_start + sample_size\n",
    "    signal = record[0][sample_start:sample_end, channel]\n",
    "\n",
    "    # plot the heart beats\n",
    "    # time scale is number of readings divided by sampling frequency\n",
    "    times = (np.arange(sample_size, dtype = 'float') + sample_start) / record[1].get('fs')\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(times, signal)\n",
    "\n",
    "    # extract annotations\n",
    "    where = np.logical_and(annotation.sample >= sample_start, annotation.sample < sample_end)\n",
    "    annots = annotation.sample[where] - sample_start\n",
    "    annotypes = np.array(annotation.symbol)\n",
    "    annotypes = annotypes[where]\n",
    "\n",
    "    # plot the annotations\n",
    "    annotimes = times[annots]\n",
    "    plt.plot(annotimes, np.ones_like(annotimes) * signal.max() * 1.4, 'ro')\n",
    "\n",
    "    # annotation codes\n",
    "    for idx, annot in enumerate(annots):\n",
    "        plt.annotate(annotypes[idx], xy = (times[annot], signal.max() * 1.1))\n",
    "\n",
    "    plt.xlim([sample_start / record[1].get('fs'), (sample_end / record[1].get('fs'))])\n",
    "    plt.xlabel('Offset')\n",
    "    plt.ylabel(record[1].get('sig_name')[channel])\n",
    "    plt.savefig(plot_path + \"ecg\", bbox_inches='tight', transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ccb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 2 channels -> MLII wave = 0\n",
    "channel = 0             \n",
    "\n",
    "# start of the sample in the file\n",
    "sample_start = 0        \n",
    "\n",
    "# number of readings (360 per second)\n",
    "sample_size = 3600      \n",
    "\n",
    "record = dataset[\"100\"][0]\n",
    "annotation = dataset[\"100\"][1]\n",
    "\n",
    "plot_ecg(channel, sample_start, sample_size, record, annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0dc6da",
   "metadata": {},
   "source": [
    "# Creazione dataset di heartbeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heartbeat(channel, sample_start, sample_size, record, annotation):\n",
    "\n",
    "    sample_end = sample_start + sample_size\n",
    "    signal = record[0][sample_start:sample_end, channel]\n",
    "\n",
    "    times = (np.arange(sample_size, dtype = 'float') + sample_start) / record[1].get('fs')\n",
    "\n",
    "    where = np.logical_and(annotation.sample >= sample_start, annotation.sample < sample_end)\n",
    "    annots = annotation.sample[where] - sample_start\n",
    "    annotypes = np.array(annotation.symbol)\n",
    "    annotypes = annotypes[where]\n",
    "\n",
    "    annotimes = times[annots]\n",
    "    \n",
    "    return (signal, times, annotypes, annotimes, annots)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heartbeat(signal, times, annotypes, annotimes, annots, title):\n",
    "\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot(times, signal)\n",
    "    plt.plot(annotimes, np.ones_like(annotimes) * signal.max() * 1.4, 'ro')\n",
    "\n",
    "    for idx, annot in enumerate(annots):\n",
    "        plt.annotate(annotypes[idx], xy = (times[annot], signal.max() * 1.1))\n",
    "        \n",
    "    title = \"Heartbeat \" + title\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.xlabel(\"Time offset\")\n",
    "    plt.ylabel(\"mV\")\n",
    "    \n",
    "    title = title.replace(\"/\", \"AAA\")\n",
    "    file_name = \"\".join(title.lower()).replace(\" \", \"_\")\n",
    "    plt.savefig(plot_path + file_name, bbox_inches='tight', transparent=True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0             \n",
    "heartbeat_size = 300 \n",
    "ds = []\n",
    "for key in dataset.keys():\n",
    "    record = dataset[key][0]\n",
    "    annotation = dataset[key][1]\n",
    "    for pos_of_annotation in annotation.sample:\n",
    "        heartbeat_start = 0 if (pos_of_annotation - 149) < 0 else pos_of_annotation - 149\n",
    "        ds.append(get_heartbeat(channel, heartbeat_start, heartbeat_size, record, annotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ds, columns=[\"signal\", \"times\", \"annotypes\", \"annotimes\", \"annots\"])\n",
    "# plot_heartbeat(df[\"signal\"][0], df[\"times\"][0],df[\"annotypes\"][0], df[\"annotimes\"][0], df[\"annots\"][0])\n",
    "print(\"Numero record:\", len(df))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5364cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete heartbeat with more one annotation and with len of signal less 300\n",
    "df1 = df[df['annotypes'].str.len() == 1]\n",
    "df1 = df1[df1['signal'].str.len() == 300]\n",
    "print(\"Numero record:\", len(df1))\n",
    "display(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c37198",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(100)\n",
    "list_of_annotypes = [\"N\", \"L\", \"R\", \"V\", \"/\", \"A\", \"S\", \"F\", \"Q\"]\n",
    "for annot in list_of_annotypes:\n",
    "    condition = df1[\"annotypes\"] == annot\n",
    "    rows = df1[condition].index.tolist()\n",
    "    row = random.sample(rows, 1)\n",
    "    record = df1.loc[row]\n",
    "    r = record.to_dict(orient=\"list\")\n",
    "    plot_heartbeat(r[\"signal\"][0], r[\"times\"][0], r[\"annotypes\"][0], r[\"annotimes\"][0], r[\"annots\"][0], annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_annotypes = [\"N\", \"L\", \"R\", \"V\", \"/\", \"A\"]\n",
    "df2 = df1[[\"signal\", \"annotypes\"]]\n",
    "df2[\"annotypes\"] = df2[\"annotypes\"].apply(lambda v: v[0])\n",
    "df2 = df2[df2[\"annotypes\"].isin(list_of_annotypes)]\n",
    "print(\"Numero record:\", len(df2))\n",
    "display(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8998242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_json(base_heartbeats_path + heartbeats_datasets, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1bbdf4",
   "metadata": {},
   "source": [
    "# Addestramento modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from d2l import tensorflow as d2l\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv1D, BatchNormalization, Activation, MaxPooling1D, LSTM, GlobalAveragePooling1D, Dense, Reshape\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_annotypes = [\"N\", \"L\", \"R\", \"V\", \"/\", \"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab9475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annots_to_onehot = {\n",
    "    \"N\": [1., 0., 0., 0., 0., 0.],\n",
    "    \"L\": [0., 1., 0., 0., 0., 0.],\n",
    "    \"R\": [0., 0., 1., 0., 0., 0.],\n",
    "    \"V\": [0., 0., 0., 1., 0., 0.],\n",
    "    \"/\": [0., 0., 0., 0., 1., 0.],\n",
    "    \"A\": [0., 0., 0., 0., 0., 1.]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_to_annots = {\n",
    "    (1., 0., 0., 0., 0., 0.): \"N\",\n",
    "    (0., 1., 0., 0., 0., 0.): \"L\",\n",
    "    (0., 0., 1., 0., 0., 0.): \"R\",\n",
    "    (0., 0., 0., 1., 0., 0.): \"V\",\n",
    "    (0., 0., 0., 0., 1., 0.): \"/\",\n",
    "    (0., 0., 0., 0., 0., 1.): \"A\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_prediction, name):\n",
    "    test_class = []\n",
    "    for x in y_prediction:\n",
    "        tmp = np.zeros(len(x))\n",
    "        tmp[np.argmax(x)] = 1\n",
    "        test_class.append(tmp)\n",
    "\n",
    "    test = [onehot_to_annots[tuple(x)] for x in y_test]\n",
    "    pred = [onehot_to_annots[tuple(x)] for x in test_class]\n",
    "\n",
    "    matrix = {}\n",
    "    for i in list_of_annotypes:\n",
    "        matrix[i] = {}\n",
    "        for j in list_of_annotypes:\n",
    "            matrix[i][j] = 0\n",
    "    for t, p in zip(test, pred):\n",
    "        matrix[t][p] += 1\n",
    "    df = pd.DataFrame(matrix)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7,7)) \n",
    "    title = \"Matrice di confusione \" + name\n",
    "    file_name = \"\".join(title.lower()).replace(\" \", \"_\")\n",
    "    ax.set_title(title)\n",
    "    heatmap = sns.heatmap(df, ax=ax, annot=True, fmt=\".0f\", linewidths=2, linecolor=\"#FFFFFF\", cmap=\"Purples\", cbar_kws={\"shrink\": .5}, square=True)\n",
    "    heatmap.set(xlabel='True class', ylabel='Predicted class')\n",
    "    a = heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation = 0, fontsize = 12)\n",
    "    b = heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation = 0, fontsize = 12)\n",
    "    fig.savefig(plot_path + file_name, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff08f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(h):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(h['accuracy'], color=\"red\", linewidth=\"2\", marker='o')\n",
    "    plt.plot(h['val_accuracy'], color=\"blue\", linewidth=\"2\", marker='o')\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(h['loss'], color=\"red\", linewidth=\"2\", marker='o')\n",
    "    plt.plot(h['val_loss'], color=\"blue\", linewidth=\"2\", marker='o')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d62be4",
   "metadata": {},
   "source": [
    "### Pre-processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c31763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(base_heartbeats_path + heartbeats_datasets, orient=\"index\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"annotypes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = df[\"annotypes\"] == \"N\"\n",
    "rows = df[condition].index.tolist()\n",
    "\n",
    "random.seed(0)\n",
    "n_rows_to_delete = 60_000\n",
    "rows_to_delete = random.sample(rows, n_rows_to_delete)\n",
    "\n",
    "df1 = df.drop(rows_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f6dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"annotypes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1['signal'].tolist()\n",
    "y = [annots_to_onehot[x] for x in df1['annotypes'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9895b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=0)\n",
    "x_train = np.asarray(x_train)\n",
    "x_test = np.asarray(x_test)\n",
    "x_val = np.asarray(x_val)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d53c6b",
   "metadata": {},
   "source": [
    "### Modello 1: paper1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"valid\", input_shape=[300, 1]),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"valid\"),\n",
    "    keras.layers.MaxPooling1D(pool_size=2, strides=2),\n",
    "    keras.layers.Conv1D(filters=128, kernel_size=3, strides=1, padding=\"valid\"),\n",
    "    keras.layers.Conv1D(filters=128, kernel_size=3, strides=1, padding=\"valid\"),\n",
    "    keras.layers.MaxPooling1D(pool_size=2, strides=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))\n",
    "# print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf62dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071bc182",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rate = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(x_test)\n",
    "plot_confusion_matrix(y_test, y_prediction, \"Paper 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e3852e",
   "metadata": {},
   "source": [
    "### Modello 2: paper2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tot = Input(shape=(300, 1), name =\"Input_tot\")\n",
    "\n",
    "# Pipeline 1\n",
    "branch1_1 = keras.layers.Conv1D(filters=8, kernel_size=4, activation='relu', name =\"branch1_1\")(input_tot)\n",
    "branch1_2 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch1_2\")(branch1_1)\n",
    "branch1_3 = keras.layers.Conv1D(filters=24, kernel_size=6, activation='relu', name =\"branch1_3\")(branch1_2)\n",
    "branch1_4 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch1_4\")(branch1_3)\n",
    "\n",
    "# Pipeline 2\n",
    "branch2_1 = keras.layers.Conv1D(filters=8, kernel_size=6, activation='relu', name =\"branch2_1\")(input_tot)\n",
    "branch2_2 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch2_2\")(branch2_1)\n",
    "branch2_3 = keras.layers.Conv1D(filters=24, kernel_size=8, activation='relu', name =\"branch2_3\")(branch2_2)\n",
    "branch2_4 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch2_4\")(branch2_3)\n",
    "\n",
    "# Pipeline 3\n",
    "branch3_1 = keras.layers.Conv1D(filters=8, kernel_size=8, activation='relu', name =\"branch3_1\")(input_tot)\n",
    "branch3_2 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch3_2\")(branch3_1)\n",
    "branch3_3 = keras.layers.Conv1D(filters=24, kernel_size=10, activation='relu', name =\"branch3_3\")(branch3_2)\n",
    "branch3_4 = keras.layers.MaxPooling1D(pool_size=2, strides=2, name =\"branch3_4\")(branch3_3)\n",
    "\n",
    "# Merge pipelines\n",
    "branch_concatenate = concatenate([branch1_4,branch2_4,branch3_4], axis=1, name=\"concatenated_layer\")\n",
    "\n",
    "flatten = keras.layers.Flatten()(branch_concatenate)\n",
    "\n",
    "dense1 = Dense(256, activation = \"relu\", name = \"dense1\")(flatten)\n",
    "dense2 = Dense(32, activation = \"relu\", name = \"dense2\")(dense1)\n",
    "output_layer = Dense(6, activation = \"softmax\", name = \"output_layer\")(dense2)\n",
    "\n",
    "model = Model(inputs=[input_tot], outputs=[output_layer])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b9b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))\n",
    "# print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f566b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rate = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dcab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(x_test)\n",
    "plot_confusion_matrix(y_test, y_prediction, \"Paper 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17979750",
   "metadata": {},
   "source": [
    "### Modello 3: WaveNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f6c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[300, 1]))\n",
    "\n",
    "for rate in (1, 2, 4, 8) * 2:\n",
    "    model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=rate))\n",
    "    \n",
    "model.add(keras.layers.Conv1D(filters=10, kernel_size=1))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(6, activation=tf.nn.softmax))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a218dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))\n",
    "# print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b63b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c77863",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rate = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905107ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(x_test)\n",
    "plot_confusion_matrix(y_test, y_prediction, \"WaveNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a91c18b",
   "metadata": {},
   "source": [
    "### Modello 4: LSTM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb50195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_lstm_model((300, 1), 6)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))\n",
    "# print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b826719",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85890db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rate = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(x_test)\n",
    "plot_confusion_matrix(y_test, y_prediction, \"LSTM 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327792b",
   "metadata": {},
   "source": [
    "### Modello 5: LSTM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "def swish(x):\n",
    "    return x * K.sigmoid(x)\n",
    "\n",
    "y = swish(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('swish(x)')\n",
    "plt.title('Swish Function')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c1a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(32, kernel_size=3, strides=1, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('swish')(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('swish')(x)\n",
    "\n",
    "    x = Conv1D(128, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('swish')(x)\n",
    "\n",
    "    x = MaxPooling1D(pool_size=2, strides=2, padding='same')(x)\n",
    "\n",
    "    x = LSTM(128, return_sequences=True, go_backwards=False, dropout=0.5)(x)\n",
    "    x = LSTM(128, return_sequences=False, go_backwards=True, dropout=0.5)(x)\n",
    "\n",
    "    x = Reshape((-1, 128))(x)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    outputs = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model((300, 1), 6)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475ca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))\n",
    "# print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rate = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(x_test)\n",
    "plot_confusion_matrix(y_test, y_prediction, \"LSTM 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd6ef37",
   "metadata": {},
   "source": [
    "### Modello 6: DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione dell'architettura della DBN\n",
    "visible = Input(shape=(300,))\n",
    "hidden1 = Dense(256, activation='relu')(visible)\n",
    "dropout1 = Dropout(0.2)(hidden1)\n",
    "hidden2 = Dense(128, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.2)(hidden2)\n",
    "hidden3 = Dense(64, activation='relu')(dropout2)\n",
    "dropout3 = Dropout(0.2)(hidden3)\n",
    "output = Dense(6, activation='softmax')(dropout3)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895ba4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))\n",
    "# print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371abf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rate = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(x_test)\n",
    "plot_confusion_matrix(y_test, y_prediction, \"DBN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195982a",
   "metadata": {},
   "source": [
    "### Modello 7: Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1866336",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Input(shape=(300, 1))\n",
    "encoded = Dense(100, activation='relu')(input_data)\n",
    "encoded = Dense(50, activation='relu')(encoded)\n",
    "decoded = Dense(100, activation='relu')(encoded)\n",
    "decoded = Dense(300, activation='sigmoid')(decoded)\n",
    "autoencoder = Model(input_data, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train, epochs=10, batch_size=128, validation_data=(x_val, x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77423a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizzare l'encoder per ottenere la rappresentazione codificata dei dati di input\n",
    "encoder = Model(input_data, encoded)\n",
    "encoded_input = encoder.predict(x_train)\n",
    "encoded_test = encoder.predict(x_test)\n",
    "\n",
    "encoded_dim = 50\n",
    "num_classes = 6\n",
    "\n",
    "# Utilizzare la rappresentazione codificata come input per la classificazione\n",
    "input_data = Input(shape=(encoded_dim,))\n",
    "classification = Dense(100, activation='relu')(input_data)\n",
    "classification = Dense(50, activation='relu')(classification)\n",
    "classification = Dense(num_classes, activation='softmax')(classification)\n",
    "model = Model(input_data, classification)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c5dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))\n",
    "# print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409decbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rate = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb16662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(x_test)\n",
    "plot_confusion_matrix(y_test, y_prediction, \"Autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d8dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5912c31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021805c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
